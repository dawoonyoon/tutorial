{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "7.4.1.gpt2_finetune_LM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rl5M6QfOnvl",
        "outputId": "b56f6392-012b-4498-b146-d7becb1a3c83"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/requirements.txt -O requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-29 01:15:11--  https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 610 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]     610  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-29 01:15:11 (35.2 MB/s) - ‘requirements.txt’ saved [610/610]\n",
            "\n",
            "Requirement already satisfied: numpy<=1.16.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.16.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.11.1)\n",
            "Requirement already satisfied: matplotlib<3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.41.1)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.2.2)\n",
            "Requirement already satisfied: transformers==3.0.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (3.0.2)\n",
            "Requirement already satisfied: sentencepiece==0.1.85 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.1.85)\n",
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.8.0.post0)\n",
            "Requirement already satisfied: gluonnlp==0.9.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.9.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (0.22.2.post1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (1.5.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.90)\n",
            "Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (3.2)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.8.1rc1)\n",
            "Requirement already satisfied: tensorflow==2.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (2.2.0)\n",
            "Requirement already satisfied: h5py<3.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (2.10.0)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.5.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (4.6.3)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (1.5.12)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 2)) (5.0.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 2)) (7.6.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 2)) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 2)) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 2)) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 2)) (5.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from html5lib->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->-r requirements.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 10)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 10)) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 10)) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 10)) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet->-r requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp==0.9.1->-r requirements.txt (line 13)) (0.29.22)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->-r requirements.txt (line 14)) (1.0.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->-r requirements.txt (line 15)) (7.1.2)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->-r requirements.txt (line 16)) (5.0.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (2.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (0.12.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (2.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (3.12.4)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 20)) (3.3.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy->-r requirements.txt (line 22)) (0.4.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy->-r requirements.txt (line 22)) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy->-r requirements.txt (line 22)) (3.10.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy->-r requirements.txt (line 22)) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->-r requirements.txt (line 24)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->-r requirements.txt (line 24)) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->-r requirements.txt (line 24)) (4.0.1)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 2)) (5.3.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 2)) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 2)) (22.0.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 2)) (1.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 2)) (5.0.5)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 2)) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 2)) (3.5.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 2)) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (0.9.4)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (5.1.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (2.11.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 2)) (1.0.18)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->-r requirements.txt (line 10)) (7.1.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (3.3.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy->-r requirements.txt (line 22)) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy->-r requirements.txt (line 22)) (3.7.4.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->-r requirements.txt (line 24)) (1.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 2)) (2.6.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r requirements.txt (line 2)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r requirements.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r requirements.txt (line 2)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r requirements.txt (line 2)) (0.7.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->-r requirements.txt (line 2)) (0.2.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (3.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy->-r requirements.txt (line 22)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 20)) (3.4.1)\n",
            "Requirement already satisfied: tensorflow==2.2.0 in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.12.4)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.2.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.36.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.16.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (56.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.28.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.10.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdnZY2hQMgOp",
        "outputId": "fca84b16-18ca-4000-ca63-497f36cdf153"
      },
      "source": [
        "!mkdir -p data_in/KOR\n",
        "!wget https://github.com/NLP-kr/tensorflow-ml-nlp-tf2/releases/download/v1.0/gpt_ckpt.zip -O gpt_ckpt.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-29 01:16:40--  https://github.com/NLP-kr/tensorflow-ml-nlp-tf2/releases/download/v1.0/gpt_ckpt.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/223835896/5fc78d00-1783-11eb-8790-e30a33628113?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210429%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210429T011640Z&X-Amz-Expires=300&X-Amz-Signature=99fd1a7e4f02c06e32322d06630f2d3f6be6f13b5b57e664a56b24e9e4192d8c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=223835896&response-content-disposition=attachment%3B%20filename%3Dgpt_ckpt.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-04-29 01:16:40--  https://github-releases.githubusercontent.com/223835896/5fc78d00-1783-11eb-8790-e30a33628113?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210429%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210429T011640Z&X-Amz-Expires=300&X-Amz-Signature=99fd1a7e4f02c06e32322d06630f2d3f6be6f13b5b57e664a56b24e9e4192d8c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=223835896&response-content-disposition=attachment%3B%20filename%3Dgpt_ckpt.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460908853 (440M) [application/octet-stream]\n",
            "Saving to: ‘gpt_ckpt.zip’\n",
            "\n",
            "gpt_ckpt.zip        100%[===================>] 439.56M  48.6MB/s    in 10s     \n",
            "\n",
            "2021-04-29 01:16:50 (43.2 MB/s) - ‘gpt_ckpt.zip’ saved [460908853/460908853]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD9XiD0VOUCs"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import gluonnlp as nlp\n",
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from transformers import TFGPT2LMHeadModel\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKfEBxueNybh",
        "outputId": "6088f79f-41f5-4d69-b15e-8be77a8e0831"
      },
      "source": [
        "!unzip -o gpt_ckpt.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  gpt_ckpt.zip\n",
            "   creating: gpt_ckpt/\n",
            "  inflating: gpt_ckpt/gpt2_kor_tokenizer.spiece  \n",
            "  inflating: gpt_ckpt/config.json    \n",
            "  inflating: gpt_ckpt/tf_model.h5    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mblQJYOsOUCz"
      },
      "source": [
        "class GPT2Model(tf.keras.Model):\n",
        "    def __init__(self, dir_path):\n",
        "        super(GPT2Model, self).__init__()\n",
        "        self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        return self.gpt2(inputs)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcRSG8VeOUC0",
        "outputId": "b048a3a5-eb78-4f39-db9c-56f54f8a8259"
      },
      "source": [
        "BASE_MODEL_PATH = './gpt_ckpt'\n",
        "gpt_model = GPT2Model(BASE_MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at ./gpt_ckpt.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB7tjacHPMvs",
        "outputId": "f4025607-a724-4cdc-a99c-55484c3db859"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.85)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_YQleVdOUC0"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 10\n",
        "MAX_LEN = 30\n",
        "TOKENIZER_PATH = './gpt_ckpt/gpt2_kor_tokenizer.spiece'\n",
        "\n",
        "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n",
        "                                               mask_token=None,\n",
        "                                               sep_token=None,\n",
        "                                               cls_token=None,\n",
        "                                               unknown_token='<unk>',\n",
        "                                               padding_token='<pad>',\n",
        "                                               bos_token='<s>',\n",
        "                                               eos_token='</s>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmmJi_6dOUC1"
      },
      "source": [
        "def tf_top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-99999):\n",
        "    _logits = logits.numpy()\n",
        "    top_k = min(top_k, logits.shape[-1])  \n",
        "    if top_k > 0:\n",
        "        indices_to_remove = logits < tf.math.top_k(logits, top_k)[0][..., -1, None]\n",
        "        _logits[indices_to_remove] = filter_value\n",
        "\n",
        "    if top_p > 0.0:\n",
        "        sorted_logits = tf.sort(logits, direction='DESCENDING')\n",
        "        sorted_indices = tf.argsort(logits, direction='DESCENDING')\n",
        "        cumulative_probs = tf.math.cumsum(tf.nn.softmax(sorted_logits, axis=-1), axis=-1)\n",
        "\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        sorted_indices_to_remove = tf.concat([[False], sorted_indices_to_remove[..., :-1]], axis=0)\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove].numpy().tolist()\n",
        "        \n",
        "        _logits[indices_to_remove] = filter_value\n",
        "    return tf.constant([_logits])\n",
        "\n",
        "\n",
        "def generate_sent(seed_word, model, max_step=100, greedy=False, top_k=0, top_p=0.):\n",
        "    sent = seed_word\n",
        "    toked = tokenizer(sent)\n",
        "    \n",
        "    for _ in range(max_step):\n",
        "        input_ids = tf.constant([vocab[vocab.bos_token],]  + vocab[toked])[None, :] \n",
        "        outputs = model(input_ids)[:, -1, :]\n",
        "        if greedy:\n",
        "            gen = vocab.to_tokens(tf.argmax(outputs, axis=-1).numpy().tolist()[0])\n",
        "        else:\n",
        "            output_logit = tf_top_k_top_p_filtering(outputs[0], top_k=top_k, top_p=top_p)\n",
        "            gen = vocab.to_tokens(tf.random.categorical(output_logit, 1).numpy().tolist()[0])[0]\n",
        "        if gen == '</s>':\n",
        "            break\n",
        "        sent += gen.replace('▁', ' ')\n",
        "        toked = tokenizer(sent)\n",
        "\n",
        "    return sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pfGB_9PCOUC1",
        "outputId": "2e68c5f5-f3b2-4e5b-f1d7-ce35d76c1e72"
      },
      "source": [
        "generate_sent('이때', gpt_model, greedy=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'이때문에 일부 전문가들은 “이번 사건은 ‘제2의 삼성’을 꿈꾸는 삼성의 내부 사정을 잘 보여주는 사례”라고 평가했다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "T1pVXaNOOUC1",
        "outputId": "5f9df109-5498-4b33-d177-95325099530e"
      },
      "source": [
        "generate_sent('이때', gpt_model, top_k=0, top_p=0.95)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'이때 유리성(유리천장)을 이용해 건물 외벽까지 들이받으면 폭발적 현상이 발생하는데 건물 외벽은 한 번 무너지면 다시 일어날 수 없게 설계된 구조로 인해 붕괴 위험이 높다는 게 주택 리모델링 전문가들의 견해다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8fdhzWCSJzH",
        "outputId": "0347921f-04d3-4d05-e204-fd354db8d9e6"
      },
      "source": [
        "!mkdir -p data_in/KOR\n",
        "!wget https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/finetune_data.txt \\\n",
        "              -O data_in/KOR/finetune_data.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-29 01:23:17--  https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/finetune_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24570 (24K) [text/plain]\n",
            "Saving to: ‘data_in/KOR/finetune_data.txt’\n",
            "\n",
            "\r          data_in/K   0%[                    ]       0  --.-KB/s               \rdata_in/KOR/finetun 100%[===================>]  23.99K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-04-29 01:23:17 (14.8 MB/s) - ‘data_in/KOR/finetune_data.txt’ saved [24570/24570]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61JQYb_GOUC2"
      },
      "source": [
        "DATA_IN_PATH = './data_in/KOR/'\n",
        "TRAIN_DATA_FILE = 'finetune_data.txt'\n",
        "\n",
        "sents = [s[:-1] for s in open(DATA_IN_PATH + TRAIN_DATA_FILE, encoding='utf-8').readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K242Tf5UOUC2"
      },
      "source": [
        "input_data = []\n",
        "output_data = []\n",
        "\n",
        "for s in sents:\n",
        "    tokens = [vocab[vocab.bos_token],]  + vocab[tokenizer(s)] + [vocab[vocab.eos_token],]\n",
        "    input_data.append(tokens[:-1])\n",
        "    output_data.append(tokens[1:])\n",
        "\n",
        "input_data = pad_sequences(input_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
        "output_data = pad_sequences(output_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
        "\n",
        "input_data = np.array(input_data, dtype=np.int64)\n",
        "output_data = np.array(output_data, dtype=np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlY23A34OUC2"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
        "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
        "    pred *= mask    \n",
        "    acc = train_accuracy(real, pred)\n",
        "\n",
        "    return tf.reduce_mean(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DErEnzw7OUC3"
      },
      "source": [
        "gpt_model.compile(loss=loss_function,\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=[accuracy_function])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivy0cmy5OUC3",
        "outputId": "1f3acb9b-c036-41d1-cd62-42292b601c80"
      },
      "source": [
        "history = gpt_model.fit(input_data, output_data, \n",
        "                    batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 5s 290ms/step - loss: 3.0277 - accuracy_function: 0.0968 - val_loss: 2.4888 - val_accuracy_function: 0.1151\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 2.5169 - accuracy_function: 0.1262 - val_loss: 2.3963 - val_accuracy_function: 0.1319\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 2.2782 - accuracy_function: 0.1396 - val_loss: 2.3822 - val_accuracy_function: 0.1456\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 2.0575 - accuracy_function: 0.1527 - val_loss: 2.3834 - val_accuracy_function: 0.1577\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 3s 157ms/step - loss: 1.8574 - accuracy_function: 0.1645 - val_loss: 2.4169 - val_accuracy_function: 0.1698\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 3s 157ms/step - loss: 1.6581 - accuracy_function: 0.1763 - val_loss: 2.4788 - val_accuracy_function: 0.1817\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 3s 157ms/step - loss: 1.4591 - accuracy_function: 0.1888 - val_loss: 2.5935 - val_accuracy_function: 0.1932\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 3s 157ms/step - loss: 1.2706 - accuracy_function: 0.2001 - val_loss: 2.6974 - val_accuracy_function: 0.2051\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 1.0687 - accuracy_function: 0.2123 - val_loss: 2.8174 - val_accuracy_function: 0.2174\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 0.9019 - accuracy_function: 0.2246 - val_loss: 2.9317 - val_accuracy_function: 0.2301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzinN5BUOUC4",
        "outputId": "4e9b0b41-2099-4129-d6f9-b8e0e4964ae2"
      },
      "source": [
        "DATA_OUT_PATH = './data_out'\n",
        "model_name = \"tf2_gpt2_finetuned_model\"\n",
        "\n",
        "save_path = os.path.join(DATA_OUT_PATH, model_name)\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "gpt_model.gpt2.save_pretrained(save_path)\n",
        "\n",
        "loaded_gpt_model = GPT2Model(save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at ./data_out/tf2_gpt2_finetuned_model.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tZzKV3DEOUC6",
        "outputId": "58232edd-07f1-4a22-eeff-d3c0d5551fb6"
      },
      "source": [
        "generate_sent('이때', gpt_model, greedy=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'지금쯤이면 이 육십 전짜리 백합 한 첩도 다 떨어졌으리라.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XJ9uScTjOUC7",
        "outputId": "4b6c0d08-20f7-48aa-8d77-6da07d6da5a6"
      },
      "source": [
        "generate_sent('이때', gpt_model, top_k=0, top_p=0.95)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'지금 이 순간에도 꼬리치기를 하며 달려가는 나의 행동에 관객석에서는 함성이 터져 나왔다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Pjex-LWOx8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}